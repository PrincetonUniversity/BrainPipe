#!/usr/bin/env python2
# -*- coding: utf-8 -*-
"""
Created on Sat Feb  4 09:55:10 2017

@author: tpisano
"""
import os, sys, shutil, multiprocessing as mp
from tools.imageprocessing import preprocessing
from tools.objectdetection.three_d_celldetection import detect_cells_in_3d, detect_cells_in_3d_checker
from tools.registration.transform import identify_structures_w_contours
from tools.registration.register import elastix_wrapper
from tools.utils.detection_testing import cellcount_arrayjob, rerun_cellcount_registration_transformation
from tools.utils.io import load_kwargs
from tools.utils.parallel import parallel_process
#%%


def run_brain_locally(pth = None, cores = None, steps=None, save_before_reorientation=False, **params):
    '''Function to mimic sending a complete batch job to the cluster
    
    Inputs:
        pth: (optional) path to folder generated by package
        steps: (optional, tuple of ints), False/None - run all steps
                             steps of which to run
        params: dict of parameters generated from run_tracing file
        save_before_reorientation (optional): keep tiff before fix_orientation command
    '''
    
    #inputs:
    if pth: params = load_kwargs(pth)
    if not cores: cores = mp.cpu_count() - 3
    
    #determine steps to run
    if not steps: steps = [0,1,2,3,4,5]
        
    #######################STEP 0 #######################
    #####################################################
    if 0 in steps:
        ###make parameter dictionary and pickle file:
        preprocessing.generateparamdict(os.getcwd(), **params) # e.g. single job assuming directory_determiner function has been properly set        
        #preprocessing.updateparams('/home/wanglab/wang/pisano/Python/lightsheet', svnm = 'param_dict_local.p', **params) # make a local copy
        if not os.path.exists(os.path.join(params['outputdirectory'], 'lightsheet')): shutil.copytree(os.getcwd(), os.path.join(params['outputdirectory'], 'lightsheet'), ignore=shutil.ignore_patterns('^.git')) #copy run folder into output to save run info
        
    #######################STEP 1 #######################    
    ##################################################### 
    if 1 in steps:
        params = load_kwargs(**params)        
        z,y,x = params['volumes'][0].fullsizedimensions
        sys.stdout.write('\n\nStarting step 1 with {} cores:\n'.format(cores)); sys.stdout.flush()
        iterlst=[]; [iterlst.append((job, cores, 1, params)) for job in range(z)]
        try:
            ###stitch, 2d cell detect, and save files; showcelldetection=True: save out cells contours ovelaid on images
            parallel_process(iterlst, process_planes_par, n_jobs=cores)
        except Exception, e:
            print('Error given\n   {}\n\nAssuming this is because raw data has been deleted. Continuing using processed data...'.format(e))
            parallel_process(iterlst, process_from_fullsizedatafld, n_jobs=cores)
        
    #######################STEP 2 #######################    
    #####################################################
    if 2 in steps:
        for jobid in range(4):
            ###check to make sure all step 1 jobs completed properly
            if jobid == 0: preprocessing.process_planes_completion_checker(**params)
            
            ###combine downsized ch and ch+cell files
            preprocessing.tiffcombiner(jobid, cores = cores, remove=True, **params)
        
    #######################STEP 3 #######################    
    #####################################################
    if 3 in steps:
        #figure out which parts to run:
        params = load_kwargs(**params)        
        
        vols = [xx.ch_type for xx in params['volumes']]
        
        #reg channel
        elastix_wrapper(0, cores=cores, **params) #run elastix
    
        #cell channel
        if 'cellch' in vols: elastix_wrapper(1, cores=cores, **params)
        
        #inj channel
        if 'injch' in vols: elastix_wrapper(2, cores=cores, **params)
        
    #######################STEP 4 #######################
    #####################################################
    if 4 in steps:
        ###4: cells###
        if 'cellch' in vols:
            for jobid in range(150):
                detect_cells_in_3d(jobid, cores=cores, mxdst=30, pln_chnk=30, ovlp_plns=25, **params) ###detect cells in 3d #import gc; gc.set_debug(gc.DEBUG_UNCOLLECTABLE; gc.set_debug(gc.DEBUG_INSTANCES);gc.set_debug(gc.DEBUG_LEAK)
        
            detect_cells_in_3d_checker(pln_chnk=30 ,**params) ###check to ensure detect_cells_in_3d worked. NOTE pln_chnk MUST equal pln_chnk from above
    
    #######################STEP 5 #######################        
    #####################################################
    if 5 in steps:
        if 'injch' in vols or 'cellch' in vols:
            for jobid in range(5):
                identify_structures_w_contours(jobid, cores=cores, make_color_images=False, consider_only_multipln_contours=True, overlay_on_original_data=False, **params) #write cells centers to txt file and transformix
        
    
    return
#%%

def process_planes_par((job, cores, compression, kwargs)):
    return preprocessing.process_planes(job, cores, compression, verbose=False, **kwargs)
    
def process_from_fullsizedatafld((job, cores, compression, kwargs)):
    return preprocessing.process_planes_from_fullsizedatafolder(job, cores, compression, verbose=False, **kwargs)
