{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ClearMap2 parameter sweep on annotated volumes\n",
    "\n",
    "The goal of this notebook is to perform a parameter sweep on a folder of tiff files that users have annotated and saved those annotations as RoiSet.zip files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up directories and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_cm2 = '/home/emilyjanedennis/Desktop/GitHub/rat_BrainPipe/ClearMap2\n",
    "src = '/Users/emilydennis/Desktop/'\n",
    "ann_folder = os.path.join(src,'mesospim_anns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import os,sys,json,glob,shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile as tif\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.spatial import distance\n",
    "sys.path.append(path_to_cm2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tiff_to_npy(src,ann_folder,this_ann_folder):\n",
    "    file_loc = os.path.join(src,ann_folder,this_ann_folder)\n",
    "    imported_tiff = tif.imread(file_loc)\n",
    "    np.save(file_loc[0:-4] + '.npy',imported_tiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ann_vals_in_np(src, ann_folder,ann_file):\n",
    "    ann_vals=[]\n",
    "    these_anns = os.listdir(os.path.join(src,ann_folder,ann_file))\n",
    "    for j in np.arange(0,len(these_anns)):\n",
    "        z = int(these_anns[j][0:4])\n",
    "        y = int(these_anns[j][5:9])\n",
    "        x = int(these_anns[j][10:14])\n",
    "        ann_vals.append([z,y,x])\n",
    "return ann_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distance_metrics_given_cdists(\n",
    "        ground_truth, predicted, y, cutoff=10, verbose=True):\n",
    "    \"\"\"\n",
    "    Function to calculate the pairwise distances\n",
    "    between two lists of zyx points.\n",
    "\n",
    "    Inputs:\n",
    "    -------\n",
    "    ground_truth, predicted: each iterable\n",
    "    consisting of ndimensional coordinates.\n",
    "    y: matrix of distances between all\n",
    "    elements of ground truth and predicted\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    paired: list of [ground_truth\"s index\n",
    "    (from input list), predicted\"s index (from input list), distance]\n",
    "    tp,fp,fn: statistics on true positives,\n",
    "    false positives, and false negatives.\n",
    "    \"\"\"\n",
    "    # only keep those distances that are below the cutoff!\n",
    "    truth_indices, pred_indices = np.where(y <= cutoff)\n",
    "    dists = zip(y[truth_indices, pred_indices], truth_indices, pred_indices)\n",
    "\n",
    "    # sort by smallest dist\n",
    "    dists = sorted(dists, key=lambda x: x[0])\n",
    "\n",
    "    used_truth = set()\n",
    "    used_pred = set()\n",
    "    paired = []\n",
    "    for (i, dist) in enumerate(dists):\n",
    "        d = dist[0]\n",
    "        if d > cutoff:\n",
    "            # we have reached distances beyond the cutoff\n",
    "            break\n",
    "        truth_idx = dist[1]\n",
    "        pred_idx = dist[2]\n",
    "        if truth_idx not in used_truth and pred_idx not in used_pred:\n",
    "            paired.append((truth_idx, pred_idx, d))\n",
    "            used_truth.add(truth_idx)\n",
    "            used_pred.add(pred_idx)\n",
    "        if len(used_truth) == len(ground_truth) or len(used_pred) == len(predicted):\n",
    "            # we have used up all the entries from the shorter list\n",
    "            break\n",
    "\n",
    "    tp = len(paired)\n",
    "    fn = len(ground_truth) - len(paired)\n",
    "    fp = len(predicted) - len(paired)\n",
    "    if verbose:\n",
    "        print(\"TP: {}, FP: {}, FN: {}\".format(tp, fp, fn))\n",
    "    # print(paired)\n",
    "\n",
    "    if verbose:\n",
    "       plt.hist([xx[2] for xx in paired], bins=np.max((int(len(paired)/500), 10)))\n",
    "       plt.title(\"Histogram of distances - pixel or microns\")\n",
    "\n",
    "    return paired, tp, fp, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_cells(source, thresholds):\n",
    "  \"\"\"Filter a array of detected cells according to the thresholds.\n",
    "  \n",
    "  Arguments\n",
    "  ---------\n",
    "  source : str, array or Source\n",
    "    The source for the cell data.\n",
    "  sink : str, array or Source\n",
    "    The sink for the results.\n",
    "  thresholds : dict\n",
    "    Dictionary of the form {name : threshold} where name refers to the \n",
    "    column in the cell data and threshold can be None, a float \n",
    "    indicating a minimal threshold or a tuple (min,max) where min,max can be\n",
    "    None or a minimal and maximal threshold value.\n",
    "  \n",
    "  Returns\n",
    "  -------\n",
    "  sink : str, array or Source\n",
    "    The thresholded cell data.\n",
    "  \"\"\"\n",
    "  \n",
    "  ids = np.ones(source.shape[0], dtype=bool);\n",
    "  for k,t in thresholds.items():\n",
    "    if t:\n",
    "      if not isinstance(t, (tuple, list)):\n",
    "        t = (t, None);\n",
    "      if t[0] is not None:\n",
    "        ids = np.logical_and(ids, t[0] <= source[k])\n",
    "      if t[1] is not None:\n",
    "        ids = np.logical_and(ids, t[1] > source[k]);\n",
    "  cells_filtered = source[ids];\n",
    "  return cells_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distance_metrics(ground_truth, predicted, cutoff=10, verbose=True):\n",
    "    \"\"\"\n",
    "    Function to calculate the pairwise distances\n",
    "    between two lists of zyx points.\n",
    "\n",
    "    Inputs:\n",
    "    -------\n",
    "    ground_truth, predicted: each iterable consisting of\n",
    "    ndimensional coordinates.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    paired: list of [ground_truth\"s index (from input list),\n",
    "    predicted\"s index (from input list), distance]\n",
    "    tp,fp,fn: statistics on true positives, false positives,\n",
    "    and false negatives.\n",
    "    \"\"\"\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\nCalculating pairwise distances...\")\n",
    "    y = distance.cdist(ground_truth, predicted, metric=\"euclidean\")\n",
    "    return pairwise_distance_metrics_given_cdists(\n",
    "       ground_truth, predicted, y, cutoff, verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for cm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "listoftiffs = [f for f in os.listdir(ann_folder) if f.find('.tif') != -1]\n",
    "listofanns = [f for f in os.listdir(ann_folder) if f.find('.RoiSet') != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import annotation volumes and reformat for CM2 if in tiff form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0,len(listoftiffs)):\n",
    "    convert_tiff_to_npy(src,ann_folder,listoftiffs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "listofnpys = [f for f in os.listdir(ann_folder) if f.find('.npy') != -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up ClearMap2: imports and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ClearMap.IO.Workspace as wsp\n",
    "import ClearMap.IO.IO as io\n",
    "import ClearMap.ImageProcessing.Experts.Cells as cells\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = ann_folder\n",
    "ws = wsp.Workspace('CellMap', directory=directory);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define CM2 parameters to sweep over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we list the parameter ranges to sweep over.\n",
    "background_sizes = [5,7,9] # will make xy tuples like: (5,5), (7,7), (9,9)  \n",
    "shape_threshold_sizes = [100, 150, 200, 250, 300, 350, 400, 450]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up basic, shared cell_detection_parameters\n",
    "cell_detection_parameter = cells.default_cell_detection_parameter.copy()\n",
    "cell_detection_parameter['illumination'] = None\n",
    "cell_detection_parameter['intensity_detection']['measure'] = ['source','background']\n",
    "\n",
    "processing_parameter = cells.default_cell_detection_processing_parameter.copy()\n",
    "processing_parameter.update(\n",
    "    processes = 'serial',\n",
    "    size_max = 100, #35,\n",
    "    size_min = 30, #30,\n",
    "    overlap  = 15, #10,\n",
    "    verbose = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CM2 Parameter sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in listofnpys:\n",
    "    ws.debug = file\n",
    "    ws.info()\n",
    "\n",
    "    for background_size,shape_threshold_size in product(background_sizes,shape_threshold_sizes):\n",
    "        this_cell_parameter_dict = cell_detection_parameter.copy()\n",
    "        this_cell_parameter_dict['background_correction']['shape'] = (background_size,background_size)\n",
    "        this_cell_parameter_dict['shape_detection']['threshold'] = shape_threshold_size\n",
    "        postfix = f'raw_bck{background_size}_shpthresh{shape_threshold_size}'\n",
    "        # actually detect cells:\n",
    "        cells.detect_cells(ws.filename('debug'), ws.filename('cells', postfix=postfix),\n",
    "            cell_detection_parameter=this_cell_parameter_dict,\n",
    "            processing_parameter=processing_parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate fp, fn, precision for each volume, save as data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOPPED HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if filt:\n",
    "                paired, tp, fp, fn = pairwise_distance_metrics(anns,filt,cutoff=30,verbose=False)\n",
    "                # add output to other outputs\n",
    "                precision = tp/(tp+fp)\n",
    "                recall = tp/(tp+fn)\n",
    "                f1 = 2*((precision*recall)/(precision+recall))\n",
    "                datatoadd = file[0:-14], sz, sz2, source, tp, fp, fn, round(precision,2), round(recall,2), round(f1,2)\n",
    "                alldata.append(datatoadd)\n",
    "    # when all loops are done, save\n",
    "    placetosave = os.path.join(trainingfolder,\"{}_filt_outputs.npy\".format(file[0:-14]))\n",
    "    np.save(placetosave,alldata)\n",
    "    df = pd.DataFrame(alldata,columns=['name','sz1','sz2','source','tp','fp','fn','p','r','f1'])\n",
    "    alldf = pd.concat([alldf,df])\n",
    "#directories and files\n",
    "a235 = ['/home/emilyjanedennis/Desktop/cells_raw.npy']\n",
    "thresholds = {'source' : 3,\n",
    "      'size'   : (30,120)\n",
    "      }\n",
    "filetosave= \"/home/emilyjanedennis/Desktop/a235_filtered.npy\"\n",
    "cells.filter_cells(source = a235, sink = filetosave, thresholds=thresholds);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(0,len(listofanns)):\n",
    "    ann_vals = get_ann_vals_in_np(src,ann_folder,listofanns[i])\n",
    "    # do bipartite matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe filter?\n",
    " # set iters you want -- should move this out of loop and to the top \n",
    "    sizes = np.arange(10,100,5)\n",
    "    sizes2 = np.arange(40,140,5)\n",
    "    alldata=[()]\n",
    "    # for this iter\n",
    "    for sz in sizes:\n",
    "        for sz2 in sizes2:\n",
    "            size = (sz,sz2)\n",
    "                #set thresholds\n",
    "            thresholds = {    \n",
    "                 'source' : 3,\n",
    "                'size'   : size}\n",
    "             #filter cells using defined below (need to import later, but had changed so source/sink = just sink)\n",
    "            filtd = filter_cells(source = np.load(os.path.join(rawfolder,file)), \n",
    "                       thresholds=thresholds);\n",
    "            filtereddata=[()]\n",
    "            #reformat filtered data this is hacky and because I'm being lazy, to change\n",
    "            for l in range(0,np.size(filtd)):\n",
    "                z, y, x, toss, toss2 = filtd[l]\n",
    "                vals = x, y, z\n",
    "                filtereddata.append(vals)\n",
    "            filt = filtereddata[1:]\n",
    "            #compare filt to ann\n",
    "            if filt:\n",
    "                paired, tp, fp, fn = pairwise_distance_metrics(anns,filt,cutoff=30,verbose=False)\n",
    "                # add output to other outputs\n",
    "                precision = tp/(tp+fp)\n",
    "                recall = tp/(tp+fn)\n",
    "                f1 = 2*((precision*recall)/(precision+recall))\n",
    "                datatoadd = file[0:-14], sz, sz2, source, tp, fp, fn, round(precision,2), round(recall,2), round(f1,2)\n",
    "                alldata.append(datatoadd)\n",
    "    # when all loops are done, save\n",
    "    placetosave = os.path.join(trainingfolder,\"{}_filt_outputs.npy\".format(file[0:-14]))\n",
    "    np.save(placetosave,alldata)\n",
    "    df = pd.DataFrame(alldata,columns=['name','sz1','sz2','source','tp','fp','fn','p','r','f1'])\n",
    "    alldf = pd.concat([alldf,df])\n",
    "#directories and files\n",
    "a235 = ['/home/emilyjanedennis/Desktop/cells_raw.npy']\n",
    "thresholds = {'source' : 3,\n",
    "      'size'   : (30,120)\n",
    "      }\n",
    "filetosave= \"/home/emilyjanedennis/Desktop/a235_filtered.npy\"\n",
    "cells.filter_cells(source = a235, sink = filetosave, thresholds=thresholds);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>63</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>398</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>159</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>278</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>63</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>387</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>14</td>\n",
       "      <td>398</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>8</td>\n",
       "      <td>384</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>21</td>\n",
       "      <td>172</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     x    y    z\n",
       "0   23   63  257\n",
       "1    7  398  137\n",
       "2   21  159  373\n",
       "3    4  278   21\n",
       "4    4   63  383\n",
       "..  ..  ...  ...\n",
       "79   1  387  170\n",
       "80  14  398   71\n",
       "81   8  384  197\n",
       "82   2   75  169\n",
       "83  21  172   49\n",
       "\n",
       "[84 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.DataFrame(ann_vals,columns=[\"z\",\"y\",\"x\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
