{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial to extract coordinates from ROIs saved ImageJ/Fiji and map to an atlas.\n",
    "Assumes:\n",
    "1. Registration (step 1, 2, 3) is complete.\n",
    "2. Points or ROIs were drawn in the sagittal registered volumes (`result.1.tif` or `result.tif`)\n",
    "3. Multiple ROIs were saved as a `.zip` file in ImageJ/Fiji\n",
    "\n",
    "In this experiment, a fiber was placed in the brain for fiber photometry, and 5 points were clicked in each fiber site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'skimage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e48e1a00f97e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtifffile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'skimage'"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import os, numpy as np, time, cv2\n",
    "from skimage.external import tifffile\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.colors\n",
    "from skimage.morphology import ball\n",
    "#change working directory\n",
    "os.chdir(\"/jukebox/wang/zahra/python/lightsheet_py3\")\n",
    "from tools.conv_net.utils.io import read_roi_zip\n",
    "from tools.registration.transform import transformed_pnts_to_allen_helper_func\n",
    "from tools.registration.register import count_structure_lister\n",
    "from tools.utils.io import load_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a prefix name (e.g. mouse name) for the files and paths to sample atlas image and ROIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wanglab/mounts/wang/zahra/python/lightsheet_py3/tutorials/supp_files/fiber_points_RoiSet.zip\n"
     ]
    }
   ],
   "source": [
    "#brainname, added as a prefix for all files\n",
    "brain = \"mouse10\"\n",
    "\n",
    "#roi pth\n",
    "roi_pth = os.path.join(os.getcwd(), \"supp_files/fiber_points_RoiSet.zip\")\n",
    "print(roi_pth)\n",
    "#downsized atlas\n",
    "atl = os.path.join(os.getcwd(), \"supp_files/pma_downsampled.tif\")\n",
    "\n",
    "#sample brain\n",
    "vol = os.path.join(os.getcwd(), \"supp_files/fiber_downsampled.tif\") \n",
    "\n",
    "#destination folder (something like)\n",
    "fld = \"/home/wanglab/Desktop\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's mport the ROIs from the `.zip` file make in ImageJ/Fiji, translate them into the coronal and horizontal orientation, and output Princeton Mouse atlas coordinates (in this case).\n",
    "\n",
    "The output will be in the destination folder set above, in a folder named `points_merged_to_atlas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "nonexistent ROIs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6074a78d438d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroi_pth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"nonexistent ROIs\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#get rois\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mzyx_rois_sag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0myy\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".roi\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mxx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mread_roi_zip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroi_pth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_roi_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#slice into diff orientations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: nonexistent ROIs"
     ]
    }
   ],
   "source": [
    "assert os.path.exists(roi_pth), \"nonexistent ROIs\"\n",
    "\n",
    "#get rois\n",
    "zyx_rois_sag = np.asarray([[int(yy) for yy in xx.replace(\".roi\", \"\").split(\"-\")] for xx in read_roi_zip(roi_pth, include_roi_name=True)])\n",
    "#slice into diff orientations\n",
    "zyx_rois_cor = np.asarray([[xx[1], xx[2], xx[0]] for xx in zyx_rois_sag])\n",
    "zyx_rois_hor = np.asarray([[xx[2], xx[1], xx[0]] for xx in zyx_rois_sag])\n",
    "\n",
    "#make destination path\n",
    "dst = os.path.join(fld, \"points_merged_to_atlas\")\n",
    "if not os.path.exists(dst): os.mkdir(dst)\n",
    "\n",
    "#export coordinates\n",
    "if os.path.exists(os.path.join(dst, \"{}_allen_coordinates.txt\".format(brain))): os.remove(os.path.join(dst, \"{}_allen_coordinates.txt\".format(brain)))\n",
    "with open(os.path.join(dst, \"{}_allen_coordinates.txt\".format(brain)), \"a\") as txt:\n",
    "    txt.write(\"Allen Atlas CCF coordinates (zyx) in the horizontal orientation:\\n%s\\n\" % zyx_rois_hor)\n",
    "    txt.write(\"\\nAllen Atlas CCF coordinates (zyx) in the saggital orientation:\\n%s\\n\" % zyx_rois_sag)\n",
    "    txt.write(\"\\nAllen Atlas CCF coordinates (zyx) in the coronal orientation:\\n%s\" % zyx_rois_cor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take the ROIs, find their mean x, y, z dimension coordinate for each site, and map it onto the atlas as a merged RBG image that you can open in ImageJ/Fiji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tifffile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-8f064f7e261c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#MERGED IMAGES TO ATLAS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#atlas (sagittal)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0matl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtifffile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0matl_cnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tifffile' is not defined"
     ]
    }
   ],
   "source": [
    "#MERGED IMAGES TO ATLAS\n",
    "#atlas (sagittal)\n",
    "atl = tifffile.imread(atl)\n",
    "atl_cnn = np.zeros_like(atl)\n",
    "\n",
    "#make a merged map for the volume as well   \n",
    "sag_site1 = zyx_rois_sag[0:5]; sag_site2 = zyx_rois_sag[5:];\n",
    "sag_site1_av = sag_site1.mean(axis = 0).astype(int); sag_site2_av = sag_site2.mean(axis = 0).astype(int)\n",
    "atl_cnn[sag_site1_av[0]-1:sag_site1_av[0]+1, sag_site1_av[1], sag_site1_av[2]] = 1\n",
    "atl_cnn[sag_site2_av[0]-1:sag_site2_av[0]+1, sag_site2_av[1], sag_site2_av[2]] = 1\n",
    "\n",
    "#apply dilation\n",
    "r = 2\n",
    "selem = ball(r)[int(r/2)]\n",
    "atl_cnn = atl_cnn.astype(\"uint8\")\n",
    "atl_cnn = np.asarray([cv2.dilate(atl_cnn[i], selem, iterations = 1) for i in range(atl_cnn.shape[0])])\n",
    " \n",
    "merged_Allen = np.stack([atl, atl_cnn, np.zeros_like(atl)], -1)\n",
    "tifffile.imsave(os.path.join(dst, \"{}_points_merged_to_atlas_sagittal.tif\".format(brain)), merged_Allen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how this look looks in each channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis(\"off\")\n",
    "plt.imshow(merged_atlas[39, :, :, 0], cmap = \"gist_yarg\", alpha = 0.5)\n",
    "plt.imshow(merged_atlas[39, :, :, 1], cmap = \"Reds\", alpha = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly we can make overlays of the the registered lightsheet image and the points that were selected in the ROIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tifffile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1ac3e7e3d07e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#get registered volumes for overlay - this will be a saggital image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtifffile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mimg_cnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tifffile' is not defined"
     ]
    }
   ],
   "source": [
    "#MERGED IMAGES TO REGISTERED VOLUMES\n",
    "#get registered volumes for overlay - this will be a saggital image\n",
    "\n",
    "img = tifffile.imread(vol)\n",
    "img_cnn = np.zeros_like(img)\n",
    "\n",
    "#make a merged map for the volume as well   \n",
    "img_cnn[sag_site1_av[0]-1:sag_site1_av[0]+1, sag_site1_av[1], sag_site1_av[2]] = 1\n",
    "img_cnn[sag_site2_av[0]-1:sag_site2_av[0]+1, sag_site2_av[1], sag_site2_av[2]] = 1\n",
    "\n",
    "#apply dilation\n",
    "r = 3\n",
    "selem = ball(r)[int(r/2)]\n",
    "img_cnn = img_cnn.astype(\"uint8\")\n",
    "img_cnn = np.asarray([cv2.dilate(img_cnn[i], selem, iterations = 1) for i in range(img_cnn.shape[0])])\n",
    "\n",
    "#make the merged saggital stack\n",
    "merged_img_sag = np.stack([img, img_cnn, np.zeros_like(img)], -1)\n",
    "tifffile.imsave(os.path.join(dst, \"{}_points_merged_to_registered_image_sagittal.tif\".format(brain)), merged_img_sag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good way to check (and perhaps quantify later) how well registration worked is to overlay the atlas image on the registered volume. Simultaenously you could also look at an overlay of the dilated points on the same RGB volume. In this data a coronal reslice gives us the best visual of the points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MERGED CORONAL IMAGES TO REGISTERED VOLUMES AND ATLAS FOR MAXIP\n",
    "#reslice\n",
    "#both these images have the same dims\n",
    "coronal_atlas = np.transpose(atl, [1, 2, 0]) #make coronal sections\n",
    "coronal_img = np.transpose(img, [1, 2, 0])\n",
    "\n",
    "print(coronal_atlas.shape, coronal_img.shape)\n",
    "\n",
    "#init\n",
    "cor_cnn = np.zeros_like(coronal_img)\n",
    "\n",
    "#make new circles marking fiber site... use this to overlay both on atlas and image\n",
    "cor_site1 = zyx_rois_cor[0:5]; cor_site2 = zyx_rois_cor[5:];\n",
    "cor_site1_av = cor_site1.mean(axis = 0).astype(int); cor_site2_av = cor_site2.mean(axis = 0).astype(int)\n",
    "cor_cnn[cor_site1_av[0]-2:cor_site1_av[0]+2, cor_site1_av[1], cor_site1_av[2]] = 1\n",
    "cor_cnn[cor_site2_av[0]-2:cor_site2_av[0]+2, cor_site2_av[1], cor_site2_av[2]] = 1\n",
    "\n",
    "#apply dilation\n",
    "r = 3\n",
    "selem = ball(r)[int(r/2)]\n",
    "cor_cnn = cor_cnn.astype(\"uint8\")\n",
    "cor_cnn = np.asarray([cv2.dilate(cor_cnn[i], selem, iterations = 1) for i in range(cor_cnn.shape[0])])\n",
    "\n",
    "#merge\n",
    "merged_atlas_coronal = np.stack([coronal_atlas, cor_cnn, np.zeros_like(coronal_atlas)], -1)\n",
    "merged_img_coronal = np.stack([coronal_img, cor_cnn, np.zeros_like(coronal_img)], -1)\n",
    "#merge both registered volume and atlas to see registration quality\n",
    "merged_img_atlas_coronal = np.stack([coronal_img, coronal_atlas, cor_cnn], -1)\n",
    "\n",
    "#save out coronal sections - based on the fact that you click 5 points in each site in sagittal sections\n",
    "tifffile.imsave(os.path.join(dst, \"{}_points_merged_to_atlas_and_registered_volume_coronal.tif\".format(brain)), merged_img_atlas_coronal.astype(\"uint16\"))\n",
    "tifffile.imsave(os.path.join(dst, \"{}_points_merged_to_atlas_coronal.tif\".format(brain)), merged_atlas_coronal.astype(\"uint16\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes if you have sparse objects (in this case, two fibers) it can be hard to see exactly where they are while scrolling through the whole brain. So you can also make smaller sections of a few z planes where each of the objects are, now that you have the ROIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next, make smaller sections to visualise site better\n",
    "z = np.nonzero(cor_cnn)[0]\n",
    "\n",
    "#find z range of sites\n",
    "site1 = z[0:(z.shape[0]/2)]; site2 = z[(z.shape[0]/2)+1:]\n",
    "zrange_site1 = range(min(site1)-1, max(site1)+2); zrange_site2 = range(min(site2)-1, max(site)+22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since you only have a few z planes now, a max projection will be appropriate and easy to visualize. Remember that the image resolution will determine how many microns you are ultimately taking the max projection by. The stacks are also separately saved as a `.tif` for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doing a max projection\n",
    "maxip1 = np.max(merged_Allen_coronal[zrange_site1], 0)\n",
    "maxip2 = np.max(merged_Allen_coronal[zrange_site2], 0)\n",
    "\n",
    "#TO REGISTERED IMAGE\n",
    "tifffile.imsave(os.path.join(dst, \"{}_points_merged_to_registered_image_coronal.tif\".format(brain)), merged_img_coronal)\n",
    "tifffile.imsave(os.path.join(dst, \"{}_points_merged_to_registered_image_coronal_site1_z{}_{}.tif\".format(brain, min(zrange_site1), max(zrange_site1))), merged_img_coronal[zrange_site1])\n",
    "tifffile.imsave(os.path.join(dst, \"{}_points_merged_to_registered_image_coronal_site2_z{}_{}.tif\".format(brain, min(zrange_site2), max(zrange_site2))), merged_img_coronal[zrange_site2])\n",
    "\n",
    "#doing a max projection\n",
    "maxip1 = np.max(merged_img_coronal[zrange_site1], 0)\n",
    "maxip2 = np.max(merged_img_coronal[zrange_site2], 0)\n",
    "\n",
    "alpha = 0.5 #determines transparency\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"white\", \"red\"]) #color makes cells pop\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(maxip1[...,0], \"gist_yarg\")\n",
    "plt.imshow(maxip1[...,1], cmap, alpha = alpha)\n",
    "plt.title(\"Points overlaid on registered volume\", fontsize = \"small\")\n",
    "plt.savefig(os.path.join(dst, \"{}_points_merged_to_registered_image_coronal_site1_maxip_z{}_{}.pdf\".format(brain, min(zrange_site1), max(zrange_site1))), dpi = 300)\n",
    "\n",
    "plt.imshow(maxip2[...,0], \"gist_yarg\")\n",
    "plt.imshow(maxip2[...,1], cmap, alpha = alpha)\n",
    "plt.title(\"Points overlaid on registered volume\", fontsize = \"small\")\n",
    "plt.savefig(os.path.join(dst, \"{}_points_merged_to_registered_image_coronal_site2_maxip_z{}_{}.pdf\".format(brain, min(zrange_site2), max(zrange_site2))), dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can further map these points (clicked in atlas space) to the corresponding lookup table containing the structures corresponding the coordinates your site is located in. This invovles a basic one-to-one mapping and outputs a lookup table with an addition `cell_count` column that has the number of points belonging to each structure, in this case.\n",
    "\n",
    "**NOTE**: this will not be accurate for this demo dataset as images have been downsampled and datatypes altered, but the idea is the same for original atlas, registered, and annotation volumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make allen structure LUT\n",
    "zyx_rois = zyx_rois_sag\n",
    "\n",
    "#convert to structure\n",
    "#path to annotation file\n",
    "ann_pth = os.path.join(os.getcwd(), \"supp_files/ann_downsampled.tif\")\n",
    "ann = tifffile.imread(ann_pth)\n",
    "points = transformed_pnts_to_allen_helper_func(list(zyx_rois), ann, order = \"ZYX\")    \n",
    "\n",
    "#make dataframe\n",
    "lut_path = os.path.join(os.getcwd(), \"supp_files/ls_id_table_w_voxelcounts.xlsx\")\n",
    "df = count_structure_lister(lut_path, *points)\n",
    "df.to_excel(os.path.join(dst, \"{}_PMA_structures.xlsx\".format(brain)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
